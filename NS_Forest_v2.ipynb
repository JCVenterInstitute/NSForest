{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import graphviz\n",
    "import numexpr\n",
    "import itertools\n",
    "from subprocess import call\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Set Parameters\n",
    "\n",
    "##Input data\n",
    "\n",
    "dataFull = pd.read_table(\"Your/data/here\",index_col = 0)\n",
    "\n",
    "#Creates dummy columns for one vs all Random Forest modeling\n",
    "dataDummy = pd.get_dummies(dataFull, columns=[\"Clusters\"], prefix = \"\", prefix_sep = \"\")\n",
    "\n",
    "#Creates matrix of cluster median expression values\n",
    "medianValues = dataFull.groupby(by=\"Clusters\").median()\n",
    "medianValues.to_csv('Function_medianValues.csv')     \n",
    "\n",
    "#Finding the number of clusters and printing that to screen (sanity check)\n",
    "PrecolNum = len(dataFull.columns)\n",
    "PostcolNum = len(dataDummy.columns)\n",
    "adjustedColumns = PrecolNum-1\n",
    "clusters2Loop=PostcolNum-PrecolNum\n",
    "#print clusters2Loop\n",
    "\n",
    "\n",
    "####Random Forest parameters\n",
    "rfTrees=1000 #Number of trees\n",
    "threads=1     #Number of threads to use, -1 is the greedy option where it will take all available CPUs/RAM\n",
    "\n",
    "####Filtering and ranking of genes from random forest parameters\n",
    "\n",
    "Median_Expression_Level = 0\n",
    "InformativeGenes = 15 #How many top genes from the Random Forest ranked features will be evaluated for binariness \n",
    "Genes_to_testing = 6    #How many top genes ranked by binary score will be evaluated in permutations by fbeta-score (as the number increases the number of permutation rises exponentially!)\n",
    "\n",
    "#### fbeta-score parameters                   \n",
    "\n",
    "betaValue = 0.5 #Set values for fbeta weighting. 1 is default f-measure. close to zero is Precision, greater than 1 weights toward Recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Function list\n",
    "\n",
    "\n",
    "def randomForest(column, dataDummy,PrecolNum,rfTrees,threads):\n",
    "    x_train = dataDummy[list(dataDummy.columns[0:PrecolNum-1])]\n",
    "    names = dataDummy.columns[0:PrecolNum-1]\n",
    "    y_train =dataDummy[column]\n",
    "    rf = RandomForestClassifier(n_estimators = rfTrees, n_jobs = threads, random_state=123456)\n",
    "    rf.fit(x_train, y_train)\n",
    "    Ranked_Features=sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), names),reverse=True)\n",
    "    return Ranked_Features\n",
    "\n",
    "def rankInformative(Ranked_Features):\n",
    "    RankedList = []\n",
    "    midcounter = 0\n",
    "    for x in Ranked_Features:\n",
    "        midcounter +=1\n",
    "        RankedList.append(x[1])\n",
    "        rankedDict[column] = RankedList\n",
    "        if midcounter==30:\n",
    "            break\n",
    "    return RankedList             \n",
    "\n",
    "def negativeOut(x, column, medianValues,Median_Expression_Level):\n",
    "    Positive_RankedList_Complete = []\n",
    "    for i in x:\n",
    "        if medianValues.loc[column, i] > Median_Expression_Level:\n",
    "            print i\n",
    "            print medianValues.loc[column, i]\n",
    "            Positive_RankedList_Complete.append(i)\n",
    "        else:\n",
    "            print i\n",
    "            print medianValues.loc[column, i]\n",
    "            print \"Is Right Out!\"\n",
    "    return Positive_RankedList_Complete\n",
    "\n",
    "def binaryScore(Positive_RankedList_Complete, informativeGenes, medianValues, column):\n",
    "    Positive_RankedList=list(Positive_RankedList_Complete[0:InformativeGenes])\n",
    "    Median_RF_Subset=medianValues.loc[:, Positive_RankedList]\n",
    "    Rescaled_Matrix=pd.DataFrame()\n",
    "    \n",
    "    for i in Positive_RankedList:\n",
    "        Target_value=medianValues.loc[column, i]\n",
    "        Rescaled_values=Median_RF_Subset[[i]].divide(Target_value)\n",
    "        Rescaled_Matrix=pd.concat([Rescaled_Matrix,Rescaled_values],axis=1)\n",
    "    difference_matrix=Rescaled_Matrix.apply(lambda x: 1-x, axis=1)\n",
    "    difference_matrix_clean = difference_matrix.where(difference_matrix > 0, 0)\n",
    "    ColumnSums=difference_matrix_clean.sum(0)\n",
    "    rescaled = ColumnSums/clusters2Loop\n",
    "\n",
    "    # Double sort so that for ties, the RF ranking prevails!     \n",
    "    Ranked_Features_df=pd.DataFrame(Ranked_Features)\n",
    "    Ranked_Features_df.rename(columns={1: 'Symbol'}, inplace=True)\n",
    "    Ranked_Features_df_indexed=Ranked_Features_df.set_index(\"Symbol\")\n",
    "    rescaled_df=pd.DataFrame(rescaled)\n",
    "    binaryAndinformation_Ranks=rescaled_df.join(Ranked_Features_df_indexed,lsuffix='_scaled', rsuffix='_informationGain')\n",
    "    binaryAndinformation_Ranks.sort_values(by=['0_scaled','0_informationGain'],ascending= [False, False], inplace = True)\n",
    "    Binary_ranked_Genes=binaryAndinformation_Ranks.index.tolist()\n",
    "    Binary_RankedList=list(Binary_ranked_Genes[0:Genes_to_testing])\n",
    "    Binary_scores=rescaled.to_dict()\n",
    "    global Binary_store_DF \n",
    "    Binary_store_DF = Binary_store_DF.append(binaryAndinformation_Ranks)\n",
    "    return Binary_RankedList\n",
    "\n",
    "def DT_cutOffs(x, column):\n",
    "    cut_dict = {}\n",
    "    for i in x:\n",
    "        filename=str(i)\n",
    "        y_train =dataDummy[column]\n",
    "        x_train = dataDummy[i]\n",
    "        X = x_train[:, None]\n",
    "        clf = tree.DecisionTreeClassifier(max_leaf_nodes=2)\n",
    "        clf = clf.fit(X, y_train)\n",
    "        threshold = clf.tree_.threshold\n",
    "        cut_dict[i]=threshold[0]\n",
    "    return cut_dict\n",
    "\n",
    "def queryGenerator(x, cut_dict):\n",
    "    queryList = []\n",
    "    for i in x:\n",
    "        str1 = i\n",
    "        current_value = cut_dict.get(str1)\n",
    "        queryString1 = str(str1)+'>='+ str(current_value)\n",
    "        queryList.append(queryString1)\n",
    "    return queryList\n",
    "\n",
    "def permutor(x):\n",
    "    binarylist2 = x\n",
    "    combs = []\n",
    "    for i in xrange(1, len(x)+1):\n",
    "        els = [list(x) for x in itertools.permutations(binarylist2, i)]\n",
    "        combs.extend(els)\n",
    "    return combs\n",
    "\n",
    "def fbetaTest(x, column,testArray, betaValue):\n",
    "    fbeta_dict = {}\n",
    "    for list in x:\n",
    "        testArray['y_pred']= 0\n",
    "        betaQuery = '&'.join(list)\n",
    "        Ineq1=dataFull.query(betaQuery)\n",
    "        testList=Ineq1.index.tolist()\n",
    "        testArray.loc[testList, 'y_pred'] = 1\n",
    "        f1 = fbeta_score(testArray['y_true'], testArray['y_pred'], average= 'binary', beta=betaValue)        \n",
    "        dictName = column+\"&\"+betaQuery\n",
    "        fbeta_dict[dictName] = f1 \n",
    "    return fbeta_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Core analysis \n",
    "rankedDict =  {}  ###gives us the top ten features from RF\n",
    "f1_store_1D = {}\n",
    "Binary_score_store_DF=pd.DataFrame()\n",
    "DT_cutoffs_store={}\n",
    "\n",
    "for column in dataDummy.columns[PrecolNum-1:PostcolNum]:\n",
    "       \n",
    "        ## Run Random Forest and get a ranked list \n",
    "        Ranked_Features= randomForest(column, dataDummy, PrecolNum, rfTrees, threads)\n",
    "        RankedList = rankInformative(Ranked_Features)\n",
    "        \n",
    "        ## Setup testArray for f-beta evaluation\n",
    "        testArray = dataDummy[[column]]\n",
    "        testArray.columns = ['y_true']\n",
    "        \n",
    "        #Rerank according to expression level and binary score\n",
    "        Positive_RankedList_Complete = negativeOut(RankedList, column, medianValues, Median_Expression_Level) \n",
    "        Binary_store_DF = pd.DataFrame()\n",
    "        Binary_RankedList = binaryScore(Positive_RankedList_Complete, InformativeGenes, medianValues, column)\n",
    "        \n",
    "        Binary_score_store_DF_extra = Binary_store_DF.assign(clusterName = column)\n",
    "        #print Binary_score_store_DF_extra\n",
    "        Binary_score_store_DF = Binary_score_store_DF.append(Binary_score_store_DF_extra)\n",
    "\n",
    "        \n",
    "        #Get expression cutoffs for f-beta testing\n",
    "        cut_dict = DT_cutOffs(Binary_RankedList,column)\n",
    "        DT_cutoffs_store[column]=cut_dict\n",
    "        \n",
    "        #Generate expression queries and run those queries using fbetaTest() function\n",
    "        queryInequalities=queryGenerator(Binary_RankedList, cut_dict)\n",
    "        FullpermutationList = permutor(queryInequalities)\n",
    "        #print len(FullpermutationList)\n",
    "        f1_store = fbetaTest(FullpermutationList, column, testArray, betaValue)\n",
    "        f1_store_1D.update(f1_store)\n",
    "       \n",
    "    \n",
    "    \n",
    "#Report generation and cleanup         \n",
    "        \n",
    "f1_store_1D_df = pd.DataFrame() #F1 store gives all results.\n",
    "f1_store_1D_df = pd.DataFrame.from_dict(f1_store_1D, orient='index')\n",
    "f1_store_1D_df.columns = [\"f-measure\"]\n",
    "f1_store_1D_df['markerCount'] = f1_store_1D_df.index.str.count('&')\n",
    "f1_store_1D_df.reset_index(level=f1_store_1D_df.index.names, inplace=True)\n",
    "\n",
    "f1_store_1D_df_done= f1_store_1D_df['index'].apply(lambda x: pd.Series(x.split('&')))\n",
    "\n",
    "NSForest_Results_Table=f1_store_1D_df.join(f1_store_1D_df_done)\n",
    "\n",
    "NSForest_Results_Table_Fin = pd.DataFrame()\n",
    "NSForest_Results_Table_Fin = NSForest_Results_Table[NSForest_Results_Table.columns[0:4]]\n",
    "\n",
    "for i, col in enumerate(NSForest_Results_Table.columns[4:11]):\n",
    "    splitResults= NSForest_Results_Table[col].astype(str).apply(lambda x: pd.Series(x.split('>='))) \n",
    "    firstOnly = splitResults[0]\n",
    "    Ascolumn = firstOnly.to_frame()\n",
    "    Ascolumn.columns = [col]\n",
    "    NSForest_Results_Table_Fin = NSForest_Results_Table_Fin.join(Ascolumn)\n",
    "    \n",
    "    \n",
    "NSForest_Results_Table_Fin.rename(columns={0:'clusterName'},inplace=True) #rename columns by position\n",
    "NSForest_Results_Table_Fin.sort_values(by=['clusterName','f-measure','markerCount'],ascending= [True, False, True], inplace = True)\n",
    "\n",
    "#Write outs\n",
    "Binary_score_store_DF.to_csv('Binary_scores_Supplmental_results.csv')\n",
    "NSForest_Results_Table_Fin.to_csv('NS-Forest_v2_results.csv')       \n",
    "\n",
    "\n",
    "#Subsets of full results \n",
    "max_grouped = NSForest_Results_Table_Fin.groupby(by=\"clusterName\")[\"f-measure\"].max()\n",
    "max_grouped.df=pd.DataFrame(max_grouped)\n",
    "max_grouped.df.to_csv('NSForest_v2_maxF-scores.csv')\n",
    "\n",
    "NSForest_Results_Table_Fin[\"f-measureRank\"] = NSForest_Results_Table_Fin.groupby(by=\"clusterName\")[\"f-measure\"].rank(ascending=False)\n",
    "topResults = NSForest_Results_Table_Fin[\"f-measureRank\"] < 50\n",
    "NSForest_Results_Table_top = NSForest_Results_Table_Fin[topResults]\n",
    "NSForest_Results_Table_top.to_csv('NSForest_v2_topResults.csv') \n",
    "\n",
    "\n",
    "    \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
